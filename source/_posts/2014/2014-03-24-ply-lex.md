---
author: chenwei
comments: true
date: 2014-03-24 16:01:51+00:00
layout: post
title: PLY(Python Lex-Yacc)：Lex部分
categories:
- Python
---

官方文档： http://www.dabeaz.com/ply/ply.html#ply_nn3

Lex: 一个词法分析器的生成器

完成一个从代码到LexToken流的转换


1. 定义词法规则

```python
tokens = keywords + [
        # Literals (identifier, integer constant, float constant, string constant, char const)
        'ID', 'DECCONST', 'HEXCONST', 'FLOATCONST', 'STRINGCONST', 'CHARCONST',

        # Operators (+,-,*,/,%,|,&,~,^,<<,>>, ||, &&, !, <, <=, >, >=, ==, !=)
        'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'MOD',
        'OR', 'AND', 'NOT', 'XOR', 'LSHIFT', 'RSHIFT',
        'LOR', 'LAND', 'LNOT',
        'LT', 'LE', 'GT', 'GE', 'EQ', 'NE',

        # Assignment (=, *=, /=, %=, +=, -=, <<=, >>=, &=, ^=, |=)
        'EQUALS', 'TIMESEQUAL', 'DIVEQUAL', 'MODEQUAL', 'PLUSEQUAL', 'MINUSEQUAL',
        'LSHIFTEQUAL','RSHIFTEQUAL', 'ANDEQUAL', 'XOREQUAL', 'OREQUAL',

        # Increment/decrement (++,--)
        'INCREMENT', 'DECREMENT', 'MODULO',

        # Structure dereference (->)
        'ARROW',

        # Ternary operator (?)
        'TERNARY',

        # Delimeters ( ) [ ] { } , . ; :
        'LPAREN', 'RPAREN',
        'LBRACKET', 'RBRACKET',
        'LBRACE', 'RBRACE',
        'COMMA', 'PERIOD', 'SEMI', 'COLON',

        'ANNOTATION',

        'CPPCOMMENT', 'COMMENT',
        # Ellipsis (...)
        'ELLIPSIS'
    ]
```

其中keywords是一个由保留字组成的一个集合，tokens则有keywords部门再加上词法规则对应的名称



2. 定义规则

对于tokens里面的每个名称，使用例如 t_name = r"..."  的方式使用正则表达式进行定义

```python
    # Integer literal
    t_DECCONST = r'[\dA-Fa-f]+([uU]|[lL]|[uU][lL]|[lL][uU])?'
    t_HEXCONST = r'(0[Xx])[\dA-Fa-f]+([uU]|[lL]|[uU][lL]|[lL][uU])?'

    # Floating literal
    t_FLOATCONST = r'((\d+)(\.\d+)(e(\+|-)?(\d+))? | (\d+)e(\+|-)?(\d+))([lL]|[fF])?'

    # String literal
    t_STRINGCONST = r'\"([^\\\n]|(\\.))*?\"'

    # Character constant 'c' or L'c'
    t_CHARCONST = r'(L)?\'([^\\\n]|(\\.))*?\''

    # Identifiers, and map to keywords
    def t_ID(t):
        r'[A-Za-z_][A-Za-z0-9_]*'  
        t.type = keywords_map.get(t.value, "ID")
        return t

    # Comment (C-Style)
    def t_COMMENT(t):
        r'/\*(.|\n)*?\*/'
        t.lexer.lineno += t.value.count('\n')
        return t

    # Comment (C++-Style)
    def t_CPPCOMMENT(t):
        r'//.*\n'
        t.lexer.lineno += 1
        return t

    def t_newline(t):
        r'\n+'
        t.lexer.lineno += t.value.count("\n")

    def t_error(t):
        #print("Illegal character: '%s'" % t.value[0])
        t.lexer.skip(1)
```

有些需要特殊处理的部分用了def t_name() 这种函数来表示

比如:

在t_ID() 里面需要对标识符进行查找，来判断是否为保留字

在t_COMMENT() 里面需要跳过注释中的'\n'来加上相应的行号，使其以代码中的行号保持一致

另外有t_error() 来对词法错误进行处理…



测试代码:


```python
    def lex_test():
        lx = lex.lex()
        fp = open(sys.argv[1])
        codes = fp.read()
        fp.close()
        lx.input(codes)
        while True:
            tok = lx.token()
            if not tok: break
            print(tok)
```

可以看到打印出的Tokens流了
